{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[optimizations](http://ruder.io/optimizing-gradient-descent/)\n",
    "\n",
    "Choosing a proper learning rate can be difficult. A learning rate that is too small leads to painfully slow convergence, while a learning rate that is too large can hinder convergence and cause the loss function to fluctuate around the minimum or even to diverge. the same learning rate applies to all parameter updates. If our data is sparse and our features have very different frequencies, we might not want to update all of them to the same extent, but perform a larger update for rarely occurring features.\n",
    "\n",
    "SGD has trouble navigating ravines, i.e. areas where the surface curves much more steeply in one dimension than in another. In these scenarios, SGD oscillates.\n",
    "\n",
    "Momentum is a method that helps accelerate SGD in the relevant direction and dampens oscillations.\n",
    "\n",
    "Adagrad: adapts the learning rate to the parameters (uses a different learning rate for every parameter), performing larger updates for infrequent and smaller updates for frequent parameters, well-suited for dealing with sparse data. Adagrad's main weakness is its accumulation of the squared gradients in the denominator: Since every added term is positive, the accumulated sum keeps growing during training. This in turn causes the learning rate to shrink and eventually become infinitesimally small.\n",
    "\n",
    "algorithms that are infeasible to compute in practice for high-dimensional data sets, e.g. second-order methods such as Newton's method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <h1>Mini-project1</h1>\n",
    "    <h2>Predict the laterality of upcoming finger movements</h2>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import dlc_bci as bci\n",
    "from types import SimpleNamespace \n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# baselines\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# from helpers import *\n",
    "from modelWrapper import *\n",
    "from callbacks import keep_best_model, store_best_model\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download/load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'> torch.Size([316, 28, 50])\n",
      "<class 'torch.LongTensor'> torch.Size([316])\n",
      "<class 'torch.FloatTensor'> torch.Size([100, 28, 50])\n",
      "<class 'torch.LongTensor'> torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "one_khz=False\n",
    "\n",
    "train = SimpleNamespace()\n",
    "train.X, train.y = bci.load(root='./data_bci', one_khz=one_khz)\n",
    "print(str(type(train.X)), train.X.size())\n",
    "print(str(type(train.y)), train.y.size())\n",
    "\n",
    "test = SimpleNamespace()\n",
    "test.X, test.y = bci.load(root='./data_bci', train=False, one_khz=one_khz)\n",
    "print(str(type(test.X)), test.X.size())\n",
    "print(str(type(test.y)), test.y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADeCAYAAAAtk/tvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nF0KITJBDF0KITJBDF0KITJBDF0KITPh/j17d+ZmgYyYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f31fe2ddc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 1\n",
    "plt.imshow(train.X[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((316, 1400), (316,), (100, 1400), (100,))"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten the X (no standardization for random forest) \n",
    "X_tr, y_tr = train.X.view(train.X.shape[0], -1).clone().numpy(), train.y.numpy() \n",
    "X_te, y_te = test.X.view(test.X.shape[0], -1).clone().numpy(), test.y.numpy() \n",
    "X_tr.shape, y_tr.shape, X_te.shape, y_te.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tune and compute test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best depth: 5\n",
      "Test score: 0.58\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb0AAAFACAYAAAAoIqKDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAHb9JREFUeJzt3Xu81XWd7/HXh4tsQMStFCKYoJkK\nSKDbS+Oom7E6XlIrLTFtRrvwyMksZzwzds5MmXOc6czDcZzOlB1K7WYaUZbTeBkz9ujMqEcpIxRN\n87rFC5AoCKTA5/yxFrTBDWyW+7fXhu/r+XjsB+v3W9/fb33257Hgze8emYkkSSUY0OwCJEnqK4ae\nJKkYhp4kqRiGniSpGIaeJKkYhp4kqRiGniSpGIaeJKkYhp4kqRiDml3Atho1alSOHz++2WVsV155\n5RWGDx/e7DK2S/aucfaucfZu282bN29JZr5pa+O2u9AbP3489913X7PL2K50dHTQ3t7e7DK2S/au\ncfaucfZu20XEkz0Z5+5NSVIxDD1JUjEMPUlSMQw9SVIxDD1JUjEMPUlSMQw9SVIxKgu9iLg6Il6I\niAWbeT8i4ksR8WhEzI+Ig6uqRZIkqHZL7xvAcVt4/3hgv/rPTODKCmuRJKm6O7Jk5h0RMX4LQ04B\nvpWZCdwdEbtGxJjMfLaqmvqrzOTlVWvoXLaSZ15cxdJXXu3V9T/89Gs8+/+e6tV1lsLeNc7eNa6k\n3u3VOow/3G9Un31eM29DNhZ4ust0Z33e60IvImZS2xpk9OjRdHR09EV9vSYzeenVZOmq2s+SVetY\nsnr99DqWrEpWr624iAd+VfEH7MDsXePsXeMK6V3b6IGsmdbSZ5/XzNCLbuZldwMzcxYwC6CtrS37\n2z3p1qxdx3Mvr+aZF1fxzLJVdL64asPr2s9qXl2zbqNldmkZxNjW4Ryw11DGtQ5l7K5DGVv/800j\nhjAgumtPY+666794xzv+oNfWVxJ71zh717iSejdk0ABah+/UZ5/XzNDrBPbqMj0OWNSkWrZo9Wtr\nWbQ+wF6sh9qy3wfbcy+vZu26jfN61M5DGNs6lIljduFdE0fXQm19sLUOZZeWwX1Wf2vLAPYY2Xf/\nk9qR2LvG2bvG2bvqNDP0bgTOi4jrgcOBl5p1PG/56te6DbTO+p9LVvxuo/EDAsaMrIXYYRN22xBm\n67fY9tx1KC2DBzbjV5EkbUFloRcR1wHtwKiI6AQ+DwwGyMyvAjcBJwCPAiuBc6qqpavM5G9+spCn\nfruyHm4reXn1mo3G7DRowIYts2MPeHMtzLrsgtxjlxYGDfQSR0na3lR59uYZW3k/gU9W9fmbExHc\n+chiBkQwtnUoh45v3eh42tjWoYwaPoQBA3rvmJokqX/Y7h4i2xtu+7Njml2CJKkJ3EcnSSqGoSdJ\nKoahJ0kqhqEnSSqGoSdJKoahJ0kqhqEnSSqGoSdJKoahJ0kqhqEnSSqGoSdJKoahJ0kqhqEnSSqG\noSdJKoahJ0kqhqEnSSqGoSdJKoahJ0kqhqEnSSqGoSdJKoahJ0kqhqEnSSqGoSdJKoahJ0kqhqEn\nSSqGoSdJKoahJ0kqhqEnSSqGoSdJKoahJ0kqhqEnSSqGoSdJKoahJ0kqhqEnSSqGoSdJKoahJ0kq\nhqEnSSqGoSdJKoahJ0kqhqEnSSqGoSdJKoahJ0kqhqEnSSqGoSdJKoahJ0kqRqWhFxHHRcTDEfFo\nRFzUzft7R8TtETE/IjoiYlyV9UiSylZZ6EXEQODLwPHAROCMiJi4ybDLgG9l5hTgEuDvqqpHkqQq\nt/QOAx7NzMcy81XgeuCUTcZMBG6vv57bzfuSJPWaQRWueyzwdJfpTuDwTcb8EjgV+CfgfcCIiNg9\nM5d2HRQRM4GZAKNHj6ajo6OqmndIK1assGcNsneNs3eNs3fVqTL0opt5ucn0hcA/R8TZwB3AM8Ca\n1y2UOQuYBdDW1pbt7e29WuiOrqOjA3vWGHvXOHvXOHtXnSpDrxPYq8v0OGBR1wGZuQh4P0BE7Ayc\nmpkvVViTJKlgVR7TuxfYLyImRMROwAzgxq4DImJURKyv4bPA1RXWI0kqXGWhl5lrgPOAW4GFwOzM\nfCAiLomIk+vD2oGHI+LXwGjg0qrqkSSpyt2bZOZNwE2bzPtcl9dzgDlV1iBJ0nrekUWSVAxDT5JU\nDENPklQMQ0+SVAxDT5JUDENPklQMQ0+SVAxDT5JUDENPklQMQ0+SVAxDT5JUDENPklQMQ0+SVAxD\nT5JUDENPklQMQ0+SVAxDT5JUDENPklQMQ0+SVAxDT5JUDENPklQMQ0+SVAxDT5JUDENPklQMQ0+S\nVAxDT5JUDENPklQMQ0+SVAxDT5JUDENPklQMQ0+SVAxDT5JUDENPklQMQ0+SVAxDT5JUDENPklQM\nQ0+SVAxDT5JUDENPklQMQ0+SVAxDT5JUDENPklQMQ0+SVIythl5EnBcRrX1RjCRJVerJlt4ewL0R\nMTsijouIqLooSZKqsNXQy8y/AvYDrgLOBh6JiL+NiH0rrk2SpF41qCeDMjMj4jngOWAN0ArMiYjb\nMvMvNrdcRBwH/BMwEPh6Zn5xk/ffAnwT2LU+5qLMvKmh30SS+pnXXnuNzs5OVq9evU3LjRw5koUL\nF1ZU1fatpaWFcePGMXjw4IaW32roRcT5wJ8AS4CvA/89M1+LiAHAI0C3oRcRA4EvA+8COqntIr0x\nMx/sMuyvgNmZeWVETARuAsY39JtIUj/T2dnJiBEjGD9+PNtyZGj58uWMGDGiwsq2T5nJ0qVL6ezs\nZMKECQ2toydbeqOA92fmk5t8+LqIeM8WljsMeDQzHwOIiOuBU4CuoZfALvXXI4FFPS1ckvq71atX\nb3PgafMigt13353Fixc3vI6ehN5NwG+7fOgIYGJm3pOZW9r+Hgs83WW6Ezh8kzEXA/8WEZ8ChgPv\n7G5FETETmAkwevRoOjo6elC21luxYoU9a5C9a5y9q+2mXLFixTYvt3btWpYvX15BRTuG1atXN/zd\n6knoXQkc3GX6lW7mdae7/9rkJtNnAN/IzH+IiHcA346IyZm5bqOFMmcBswDa2tqyvb29B2VrvY6O\nDuxZY+xd4+wdLFy4sKHdlO7e3LKWlhamTZvW0LI9uWQhMnNDWNUDqSdh2Qns1WV6HK/ffflRYHZ9\nvXcBLdR2p0qSesGyZcv4yle+ss3LnXDCCSxbtqyCipqrJ6H3WEScHxGD6z+fBh7rwXL3AvtFxISI\n2AmYAdy4yZingGMBIuJAaqHX+M5aSdJGNhd6a9eu3eJyN910E7vuumtVZTVNT0LvE8AfAM/w++Ny\nM7e2UGauAc4DbgUWUjtL84GIuCQiTq4P+3Pg4xHxS+A64OyuW5WSpDfmoosu4je/+Q1Tp07l0EMP\nZfr06XzoQx/ioIMOAuC9730vhxxyCJMmTWLWrFkblhs/fjxLlizhiSee4MADD+TjH/84kyZN4t3v\nfjerVq1q1q/zhm11N2VmvkBtK22b1a+5u2mTeZ/r8vpB4MhG1i1J25Mv/MsDPLjo5R6NXbt2LQMH\nDtzquIl77sLnT5q0xTFf/OIXWbBgAffffz8dHR2ceOKJLFiwYMMp/1dffTW77bYbq1at4tBDD+XU\nU09l991332gdjzzyCNdddx1f+9rX+OAHP8gPfvADzjrrrB79Lv1NT67Ta6F27G0Std2PAGTmRyqs\nS5JUgcMOO2yja9y+9KUvccMNNwDw9NNP88gjj7wu9CZMmMDUqVMBOOSQQ3jiiSf6rN7e1pMTUr4N\nPAT8N+AS4ExquyslST20tS2yrqo8e3P48OEbXnd0dPDTn/6Uu+66i2HDhtHe3t7t3WOGDBmy4fXA\ngQO3692bPTmm99bM/Gvglcz8JnAicFC1ZUmSesOIESM2e83fSy+9RGtrK8OGDeOhhx7i7rvv7uPq\n+l5PtvReq/+5LCImU7v/5vjKKpIk9Zrdd9+dI488ksmTJzN06FBGjx694b3jjjuOr371q0yZMoX9\n99+fI444oomV9o2ehN6s+vP0/oraJQc7A39daVWSpF7z3e9+t9v5Q4YM4eabb+72vfXH7UaNGsWC\nBQs2zL/wwgt7vb6+tMXQq99U+uXMfBG4A9inT6qSJKkCWzymV7/7ynl9VIskSZXqyYkst0XEhRGx\nV0Tstv6n8sokSeplPTmmt/56vE92mZe4q1OStJ3pyR1ZGntSnyRJ/UxP7sjyx93Nz8xv9X45kiRV\npyfH9A7t8nMUtQe/nrylBSRJ26edd94ZgEWLFnHaaad1O6a9vZ377rtvi+u54oorWLly5Ybp/vKo\nop7s3vxU1+mIGEnt1mSSpB3UnnvuyZw5cxpe/oorruCss85i2LBhQO1RRf1BT7b0NrUS2K+3C5Ek\n9b6//Mu/3Oh5ehdffDFf+MIXOPbYYzn44IM56KCD+PGPf/y65Z544gkmT54MwKpVq5gxYwZTpkzh\n9NNP3+jem+eeey5tbW1MmjSJz3/+80DtJtaLFi1i+vTpTJ8+Hfj9o4oALr/8ciZPnszkyZO54oor\nNnxeXzzCqCfH9P6F2tmaUAvJidSfdi5J6qGbL4LnftWjoUPXroGBPTi5fo+D4PgvbnHIjBkz+Mxn\nPsOf/umfAjB79mxuueUWLrjgAnbZZReWLFnCEUccwcknn0xEdLuOK6+8kmHDhjF//nzmz5/PwQcf\nvOG9Sy+9lN122421a9dy7LHHMn/+fM4//3wuv/xy5s6dy6hRozZa17x587jmmmu45557yEwOP/xw\njjnmGFpbW/vkEUY9uWThsi6v1wBPZmZnr1YhSarEtGnTeOGFF1i0aBGLFy+mtbWVMWPGcMEFF3DH\nHXcwYMAAnnnmGZ5//nn22GOPbtdxxx13cP755wMwZcoUpkyZsuG92bNnM2vWLNasWcOzzz7Lgw8+\nuNH7m/qP//gP3ve+92142sP73/9+7rzzTk4++eQ+eYRRT0LvKeDZzFwNEBFDI2J8ZvZ+NZK0o9rK\nFllXq3r50UKnnXYac+bM4bnnnmPGjBlce+21LF68mHnz5jF48GDGjx/f7SOFuupuK/Dxxx/nsssu\n495776W1tZWzzz57q+vJzM2+1xePMOrJMb3vA+u6TK+tz5MkbQdmzJjB9ddfz5w5czjttNN46aWX\nePOb38zgwYOZO3cuTz755BaXP/roo7n22msBWLBgAfPnzwfg5ZdfZvjw4YwcOZLnn39+o5tXb+6R\nRkcffTQ/+tGPWLlyJa+88go33HADRx11VC/+tlvWky29QZn56vqJzHw1InaqsCZJUi+aNGkSy5cv\nZ+zYsYwZM4YzzzyTk046iba2NqZOncoBBxywxeXPPfdczjnnHKZMmcLUqVM57LDDAHj729/OtGnT\nmDRpEvvssw9HHnnkhmVmzpzJ8ccfz5gxY5g7d+6G+QcffDBnn332hnV87GMfY9q0aX32NPbY0qYm\nQETcBvyfzLyxPn0KcH5mHtsH9b1OW1tbbu36EG2so6OD9vb2ZpexXbJ3jbN3sHDhQg488MBtXq7K\nJ6fvCLrra0TMy8y2rS3bky29TwDXRsQ/16c7gW7v0iJJUn/Wk4vTfwMcERE7U9sy7P6585Ik9XNb\nPZElIv42InbNzBWZuTwiWiPif/VFcZK0vdvaISRtmzfaz56cvXl8Zm64YVr9KeonvKFPlaQCtLS0\nsHTpUoOvl2QmS5cupaWlpeF19OSY3sCIGJKZv4PadXrAkK0sI0nFGzduHJ2dnSxevHibllu9evUb\n+od9R9bS0sK4ceMaXr4nofcd4PaIuKY+fQ7wzYY/UZIKMXjwYCZM2PZHknZ0dDBt2rQKKlJPTmT5\n+4iYD7wTCOAWYO+qC5Mkqbf19CkLz1G7K8upwLHAwsoqkiSpIpvd0ouItwEzgDOApcD3qF2yML2P\napMkqVdtaffmQ8CdwEmZ+ShARFzQJ1VJklSBLe3ePJXabs25EfG1iDiW2jE9SZK2S5sNvcy8ITNP\nBw4AOoALgNERcWVEvLuP6pMkqdds9USWzHwlM6/NzPcA44D7gYsqr0ySpF7W07M3AcjM32bm/83M\nP6qqIEmSqrJNoSdJ0vbM0JMkFcPQkyQVw9CTJBXD0JMkFcPQkyQVw9CTJBXD0JMkFcPQkyQVw9CT\nJBXD0JMkFcPQkyQVo9LQi4jjIuLhiHg0Il73ZIaI+MeIuL/+8+uIWFZlPZKksm3pyelvSEQMBL4M\nvAvoBO6NiBsz88H1YzLzgi7jPwVMq6oeSZKq3NI7DHg0Mx/LzFeB64FTtjD+DOC6CuuRJBWuytAb\nCzzdZbqzPu91ImJvYALwswrrkSQVrrLdm0B0My83M3YGMCcz13a7ooiZwEyA0aNH09HR0SsFlmLF\nihX2rEH2rnH2rnH2rjpVhl4nsFeX6XHAos2MnQF8cnMrysxZwCyAtra2bG9v76USy9DR0YE9a4y9\na5y9a5y9q06VuzfvBfaLiAkRsRO1YLtx00ERsT/QCtxVYS2SJFUXepm5BjgPuBVYCMzOzAci4pKI\nOLnL0DOA6zNzc7s+JUnqFVXu3iQzbwJu2mTe5zaZvrjKGiRJWs87skiSimHoSZKKYehJkoph6EmS\nimHoSZKKYehJkoph6EmSimHoSZKKYehJkoph6EmSimHoSZKKYehJkoph6EmSimHoSZKKYehJkoph\n6EmSimHoSZKKYehJkoph6EmSimHoSZKKYehJkoph6EmSimHoSZKKYehJkoph6EmSimHoSZKKYehJ\nkoph6EmSimHoSZKKYehJkoph6EmSimHoSZKKYehJkoph6EmSimHoSZKKYehJkoph6EmSimHoSZKK\nYehJkoph6EmSilFm6L26stkVSJKaoLzQe/UVuOY4+Le/hnXrml2NJKkPlRd6g1pg3KHwX1+CH3wE\nXlvd7IokSX1kULML6HMDBsIJl8Gub4HbPgfLn4MZ34VhuzW7MklSxcrb0gOIgCM/DadeBc/Mg6ve\nDS8+0eyqJEkVKzP01jvoNPjwj+CVF+Dr74Rnft7siiRJFao09CLiuIh4OCIejYiLNjPmgxHxYEQ8\nEBHfrbKebo0/Ej56GwwaCt84ER6+pc9LkCT1jcpCLyIGAl8GjgcmAmdExMRNxuwHfBY4MjMnAZ+p\nqp4tetP+8LGfwqi3wfVnwL1XNaUMSVK1qtzSOwx4NDMfy8xXgeuBUzYZ83Hgy5n5IkBmvlBhPVs2\nYjSc/a/w1nfBv/4Z3PZ5L2mQpB1MlaE3Fni6y3RnfV5XbwPeFhH/GRF3R8RxFdazdUN2rp3Jecg5\n8J9XwA8/Dmt+19SSJEm9p8pLFqKbednN5+8HtAPjgDsjYnJmLttoRREzgZkAo0ePpqOjo9eL3cjO\np/CWCWvYZ8G3Wfb0QyyY/FnWDN652s+s0IoVK6rv2Q7K3jXO3jXO3lWnytDrBPbqMj0OWNTNmLsz\n8zXg8Yh4mFoI3tt1UGbOAmYBtLW1ZXt7e1U1dzEd5h/Drj86lz98+BI48/vQuncffG7v6+jooG96\ntuOxd42zd42zd9WpcvfmvcB+ETEhInYCZgA3bjLmR8B0gIgYRW1352MV1rRtpnwAPnxD7QL2q94F\ni37R7IokSW9AZaGXmWuA84BbgYXA7Mx8ICIuiYiT68NuBZZGxIPAXOC/Z+bSqmpqyISj4KO3wsCd\n4JoT4df/1uyKJEkNqvQ6vcy8KTPflpn7Zual9Xmfy8wb668zM/8sMydm5kGZeX2V9TTszQfWLmnY\nfV+4bgbcd02zK5IkNaDsO7JsixF7wDk3w75/BD/5DNx+CeSm5+VIkvozQ29bDNkZzrgeDv5juPMf\n4IczYc2rza5KktRD5T1l4Y0aOAhO+hLsujf87G9g+bNw+ndg6K7NrkyStBVu6TUiAo6+EN43C566\nG64+DpY9vfXlJElNZei9EW8/Hc76Abz8TO0pDc/+stkVSZK2wNB7o/Y5Bj5yKwwYBNecAI/8tNkV\nSZI2w9DrDaMn1i5p2G0CfPeD8PNvNbsiSVI3DL3essuY2iUN+7TDjZ+Cn13qJQ2S1M8Yer1pyAj4\n0Pdg2llwx9/DDZ/wkgZJ6ke8ZKG3DRwMJ/9z7ZKGuZfWL2n4NrSMbHZlklQ8t/SqEAHH/AW890p4\n8j9rlzS81NnsqiSpeIZelaZ+CM6cUwu8r78LnvtVsyuSpKIZelXbdzp85Jba66uPh0dvb249klQw\nQ68vjJ5Uu6Shde/aJQ2/+E6zK5KkIhl6fWXk2NolDeOPgh9/Eub+nZc0SFIfM/T6UssucOb3YeqZ\n8O9frIXf2teaXZUkFcNLFvrawMFwypdh5F614Ht5EXzwW7VAlCRVyi29ZoiA6Z+thd8Td8I1x9fC\nT5JUKUOvmaadBR+aDS8+WXtKw/MPNLsiSdqhGXrN9tZj4SM3Q66rXcT+WEezK5KkHZbH9PqDPQ6q\nXdJw7QfgO6fCO78Au+3Ta6vffcmv4KGVvba+kti7xtm7xhXVuxGjYewhffZxkdvZafNtbW153333\nNbuMaqx+Cb73YXj835tdiST1jQNPrt2f+A2KiHmZ2ba1cW7p9SctI+HDN8ALD8K6tb222vvmzaPt\nkL77n9SOxN41zt41rqje9fHN+A29/mbAwNruzl604tfLYM+pvbrOUti7xtm7xtm76ngiiySpGIae\nJKkYhp4kqRiGniSpGIaeJKkYhp4kqRiGniSpGIaeJKkYhp4kqRiGniSpGNvdDacjYjHwZLPr2M6M\nApY0u4jtlL1rnL1rnL3bdntn5pu2Nmi7Cz1tu4i4ryd3H9fr2bvG2bvG2bvquHtTklQMQ0+SVAxD\nrwyzml3AdszeNc7eNc7eVcRjepKkYrilJ0kqhqEnSSqGobcDiYi9ImJuRCyMiAci4tP1+btFxG0R\n8Uj9z9Zm19pfRcTAiPhFRPykPj0hIu6p9+57EbFTs2vsjyJi14iYExEP1b9/7/B71zMRcUH97+uC\niLguIlr83lXH0NuxrAH+PDMPBI4APhkRE4GLgNszcz/g9vq0uvdpYGGX6f8N/GO9dy8CH21KVf3f\nPwG3ZOYBwNup9dDv3VZExFjgfKAtMycDA4EZ+L2rjKG3A8nMZzPz5/XXy6n9wzMWOAX4Zn3YN4H3\nNqfC/i0ixgEnAl+vTwfwR8Cc+hB7142I2AU4GrgKIDNfzcxl+L3rqUHA0IgYBAwDnsXvXWUMvR1U\nRIwHpgH3AKMz81moBSPw5uZV1q9dAfwFsK4+vTuwLDPX1Kc7qf0nQhvbB1gMXFPfNfz1iBiO37ut\nysxngMuAp6iF3UvAPPzeVcbQ2wFFxM7AD4DPZObLza5nexAR7wFeyMx5XWd3M9RrfF5vEHAwcGVm\nTgNewV2ZPVI/znkKMAHYExgOHN/NUL93vcTQ28FExGBqgXdtZv6wPvv5iBhTf38M8EKz6uvHjgRO\njogngOup7V66Ati1vtsJYBywqDnl9WudQGdm3lOfnkMtBP3ebd07gcczc3Fmvgb8EPgD/N5VxtDb\ngdSPQV0FLMzMy7u8dSPwJ/XXfwL8uK9r6+8y87OZOS4zx1M7keBnmXkmMBc4rT7M3nUjM58Dno6I\n/euzjgUexO9dTzwFHBERw+p/f9f3zu9dRbwjyw4kIv4QuBP4Fb8/LvU/qB3Xmw28hdpfsg9k5m+b\nUuR2ICLagQsz8z0RsQ+1Lb/dgF8AZ2Xm75pZX38UEVOpnQC0E/AYcA61/1T7vduKiPgCcDq1s69/\nAXyM2jE8v3cVMPQkScVw96YkqRiGniSpGIaeJKkYhp4kqRiGniSpGIae1M9ExMURcWEDy02NiBPe\n6HqkHZmhJ+04pgInbHWUVDBDT+oHIuJ/RsTDEfFTYP/6vH0j4paImBcRd0bEAfX534iIr9bn/Toi\n3lN/3tolwOkRcX9EnF5f9cSI6IiIxyLi/Ob8dlL/MWjrQyRVKSIOoXbrs2nU/k7+nNqd9mcBn8jM\nRyLicOAr1O4JCjAeOAbYl9otq94KfI7ac9nOq6/3YuAAYDowAng4Iq6s3+NRKpKhJzXfUcANmbkS\nICJuBFqo3Xj4+7VbMgIwpMsyszNzHfBIRDxGLdy686/121f9LiJeAEZTu0G0VCRDT+ofNr0f4ABq\nz1Sb2sPxm7ufYNf7Na7Fv/MqnMf0pOa7A3hfRAyNiBHAScBK4PGI+ADUnqAREW/vsswHImJAROxL\n7SGuDwPLqe3GlLQZhp7UZJn5c+B7wP3UnoV4Z/2tM4GPRsQvgQeoPWx0vYeBfwdupnbcbzW1Y3sT\nNzmRRVIXPmVB2s5ExDeAn2TmnGbXIm1v3NKTJBXDLT1JUjHc0pMkFcPQkyQVw9CTJBXD0JMkFcPQ\nkyQV4/8DBzDEDKyuonMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f085eb60dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "depths = np.arange(5, 100, 10) # grid search on a parameter of the model\n",
    "\n",
    "# here we store all the scores obtained with the different depths\n",
    "randForest = {\n",
    "    \"tr_scores\": [],\n",
    "    \"va_scores\": []\n",
    "}\n",
    "\n",
    "for depth in depths:\n",
    "    result = cross_validate(\n",
    "        RandomForestClassifier(n_estimators=100, max_depth=depth, n_jobs=-1, random_state=1), \n",
    "        X_tr, y_tr, cv=5, return_train_score=True)\n",
    "    \n",
    "    randForest[\"tr_scores\"].append(np.mean(result[\"train_score\"]))\n",
    "    randForest[\"va_scores\"].append(np.mean(result[\"test_score\"]))\n",
    "    \n",
    "plot_scores(depths, \"depth\", randForest[\"tr_scores\"], randForest[\"va_scores\"], ylog_scale=False)\n",
    "\n",
    "best_depth = depths[np.argmax(randForest[\"va_scores\"])]\n",
    "print('Best depth:', best_depth)\n",
    "print('Test score:',\n",
    "      RandomForestClassifier(n_estimators=100, max_depth=depth, n_jobs=-1, random_state=1)\n",
    "      .fit(X_tr, y_tr)\n",
    "      .score(X_te, y_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((316, 1400), (316,), (100, 1400), (100,))"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten and normalize the X\n",
    "X_tr, y_tr = train.X.view(train.X.shape[0], -1).clone().numpy(), train.y.numpy() \n",
    "X_te, y_te = test.X.view(test.X.shape[0], -1).clone().numpy(), test.y.numpy() \n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_tr = scaler.transform(X_tr)\n",
    "X_te = scaler.transform(X_te)\n",
    "X_tr.shape, y_tr.shape, X_te.shape, y_te.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tune and compute test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lambda: 0.215443469003\n",
      "Test score: 0.7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb0AAAFECAYAAACzs+CVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f085ea2f128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lambdas = np.logspace(-6, 6, 10) # grid search on a parameter of the model\n",
    "\n",
    "# here we store all the scores obtained with the different lambdas\n",
    "logreg = {\n",
    "    \"tr_scores\": [],\n",
    "    \"va_scores\": []\n",
    "}\n",
    "\n",
    "# tune the model on the train set \n",
    "for lambda_ in lambdas:\n",
    "    result = cross_validate(LogisticRegression(C=lambda_), X_tr, y_tr, cv=5, return_train_score=True)\n",
    "    \n",
    "    logreg[\"tr_scores\"].append(np.mean(result[\"train_score\"]))\n",
    "    logreg[\"va_scores\"].append(np.mean(result[\"test_score\"]))\n",
    "    \n",
    "plot_scores(lambdas, \"1/lambda\", logreg[\"tr_scores\"], logreg[\"va_scores\"], ylog_scale=True)\n",
    "\n",
    "# select the best lambdas and estimate the accuracy on the test set\n",
    "best_lambda = lambdas[np.argmax(logreg[\"va_scores\"])]\n",
    "print('Best lambda:', best_lambda)\n",
    "print('Test score:', \n",
    "      LogisticRegression(C=best_lambda)\n",
    "      .fit(X_tr, y_tr)\n",
    "      .score(X_te, y_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((316, 1400), (316,), (100, 1400), (100,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten and normalize the X\n",
    "X_tr, y_tr = train.X.view(train.X.shape[0], -1).clone().numpy(), train.y.numpy() \n",
    "X_te, y_te = test.X.view(test.X.shape[0], -1).clone().numpy(), test.y.numpy() \n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_tr = scaler.transform(X_tr)\n",
    "X_te = scaler.transform(X_te)\n",
    "X_tr.shape, y_tr.shape, X_te.shape, y_te.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tune and compute test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.logspace(-6, 6, 10) # grid search on a parameter of the model\n",
    "\n",
    "# here we store all the scores obtained with the different lambdas\n",
    "logreg = {\n",
    "    \"tr_scores\": [],\n",
    "    \"va_scores\": []\n",
    "}\n",
    "\n",
    "# tune the model on the train set \n",
    "for lambda_ in lambdas:\n",
    "    result = cross_validate(SVC(C=lambda_), X_tr, y_tr, cv=5, return_train_score=True)\n",
    "    \n",
    "    logreg[\"tr_scores\"].append(np.mean(result[\"train_score\"]))\n",
    "    logreg[\"va_scores\"].append(np.mean(result[\"test_score\"]))\n",
    "    \n",
    "plot_scores(lambdas, \"1/lambda\", logreg[\"tr_scores\"], logreg[\"va_scores\"], ylog_scale=True)\n",
    "\n",
    "# select the best lambdas and estimate the accuracy on the test set\n",
    "best_lambda = lambdas[np.argmax(logreg[\"va_scores\"])]\n",
    "print('Best lambda:', best_lambda)\n",
    "print('Test score:', \n",
    "      SVC(C=best_lambda)\n",
    "      .fit(X_tr, y_tr)\n",
    "      .score(X_te, y_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten and normalize the X\n",
    "X_tr, y_tr = train.X.view(train.X.shape[0], -1).clone().numpy(), train.y.numpy() \n",
    "X_te, y_te = test.X.view(test.X.shape[0], -1).clone().numpy(), test.y.numpy() \n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_tr = scaler.transform(X_tr)\n",
    "X_te = scaler.transform(X_te)\n",
    "X_tr.shape, y_tr.shape, X_te.shape, y_te.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tune and compute test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tols = np.logspace(-6, 1, 10) # grid search on a parameter of the model\n",
    "\n",
    "# here we store all the scores obtained with the different lambdas\n",
    "logreg = {\n",
    "    \"tr_scores\": [],\n",
    "    \"va_scores\": []\n",
    "}\n",
    "\n",
    "# tune the model on the train set \n",
    "for tol in tols:\n",
    "    result = cross_validate(LinearDiscriminantAnalysis(tol=tol), X_tr, y_tr, cv=5, return_train_score=True)\n",
    "    \n",
    "    logreg[\"tr_scores\"].append(np.mean(result[\"train_score\"]))\n",
    "    logreg[\"va_scores\"].append(np.mean(result[\"test_score\"]))\n",
    "    \n",
    "plot_scores(tols, \"tol\", logreg[\"tr_scores\"], logreg[\"va_scores\"], ylog_scale=True)\n",
    "\n",
    "# select the best lambdas and estimate the accuracy on the test set\n",
    "best_tol = tols[np.argmax(logreg[\"va_scores\"])]\n",
    "print('Best tol:', best_tol)\n",
    "print('Test score:', \n",
    "      LinearDiscriminantAnalysis(tol=best_tol)\n",
    "      .fit(X_tr, y_tr)\n",
    "      .score(X_te, y_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((316, 20), (316,), (100, 20), (100,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten, normalize the X and apply PCA to reduce dimensions (reduce curse of dimensionality effect)\n",
    "X_tr, y_tr = train.X.view(train.X.shape[0], -1).clone().numpy(), train.y.numpy() \n",
    "X_te, y_te = test.X.view(test.X.shape[0], -1).clone().numpy(), test.y.numpy() \n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_tr_scaled = scaler.transform(X_tr)\n",
    "X_te_scaled = scaler.transform(X_te)\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "pca.fit(X_tr_scaled)\n",
    "X_tr = pca.transform(X_tr)\n",
    "X_te = pca.transform(X_te)\n",
    "\n",
    "X_tr.shape, y_tr.shape, X_te.shape, y_te.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tune and compute test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 8\n",
      "Test score: 0.54\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb0AAAFACAYAAAAoIqKDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVHoiIpIwVHoiIpIw/j/7Lzfkr540IAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd6f0546470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Ks = np.arange(1, 10, 1) # grid search on a parameter of the model\n",
    "\n",
    "# here we store all the scores obtained with the different number of neighbors\n",
    "nearestNeig = {\n",
    "    \"tr_scores\": [],\n",
    "    \"va_scores\": []\n",
    "}\n",
    "\n",
    "for k in Ks:\n",
    "    result = cross_validate(\n",
    "        KNeighborsClassifier(n_neighbors=k), \n",
    "        X_tr, y_tr, cv=5, return_train_score=True)\n",
    "    \n",
    "    nearestNeig[\"tr_scores\"].append(np.mean(result[\"train_score\"]))\n",
    "    nearestNeig[\"va_scores\"].append(np.mean(result[\"test_score\"]))\n",
    "    \n",
    "plot_scores(Ks, \"# Neighbors\", nearestNeig[\"tr_scores\"], nearestNeig[\"va_scores\"], ylog_scale=False)\n",
    "\n",
    "best_k = Ks[np.argmax(nearestNeig[\"va_scores\"])]\n",
    "print('Best k:', best_k)\n",
    "print('Test score:', \n",
    "      KNeighborsClassifier(n_neighbors=k)\n",
    "      .fit(X_tr, y_tr)\n",
    "      .score(X_te, y_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN: 2D convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([316, 1, 28, 50]),\n",
       " torch.Size([316]),\n",
       " torch.Size([100, 1, 28, 50]),\n",
       " torch.Size([100]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a channel to store the pixels image (so to apply the 2D convolutional layer)\n",
    "X_tr, y_tr = Variable(train.X.clone().unsqueeze(1)), Variable(train.y)\n",
    "X_te, y_te = Variable(test.X.clone().unsqueeze(1)), Variable(test.y)\n",
    "\n",
    "X_tr.shape, y_tr.shape, X_te.shape, y_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2D(modelWrapper):\n",
    "    def __init__(self, nb_hidden=50, activation = nn.ReLU):\n",
    "        super(CNN2D, self).__init__()    \n",
    "        \n",
    "        self.nb_hidden = nb_hidden\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.activation = activation\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=(3, 7), padding=(1, 3)),\n",
    "            nn.MaxPool2d(2),\n",
    "            self.activation(),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d((2, 5)),\n",
    "            self.activation(),\n",
    "            \n",
    "            nn.Conv2d(64, 32, kernel_size=5, padding=2),\n",
    "            nn.MaxPool2d(2, padding=(1, 1)),\n",
    "            self.activation(),\n",
    "        )\n",
    "        \n",
    "        self.num_features = 384\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.num_features, nb_hidden),\n",
    "            self.activation(),\n",
    "            nn.Linear(nb_hidden, 2)\n",
    "        )\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = Adam(self.parameters(), lr=0.001)\n",
    "    \n",
    "    def clear(self):\n",
    "        self.__init__(self.nb_hidden, self.activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_tr, y_tr, X_test=X_te, y_test=y_te, epochs=1000, callbacks=[keep_best_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate_n_hidden(CNN2D, X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1D convolution +  dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([316, 28, 50]),\n",
       " torch.Size([316]),\n",
       " torch.Size([100, 28, 50]),\n",
       " torch.Size([100]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr, y_tr = Variable(train.X), Variable(train.y)\n",
    "X_te, y_te = Variable(test.X), Variable(test.y)\n",
    "\n",
    "X_tr.shape, y_tr.shape, X_te.shape, y_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the network with two convolutional layers\n",
    "class CNN_1D_Dropout(modelWrapper):\n",
    "    def __init__(self, nb_hidden=50, activation=nn.ReLU):\n",
    "        super(CNN_1D_Dropout, self).__init__()\n",
    "        \n",
    "        self.nb_hidden = nb_hidden\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.dropout = nn.Dropout\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(28, 64, kernel_size=5, padding=2),\n",
    "            self.activation(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Conv1d(64, 64, kernel_size=5, padding=2),\n",
    "            nn.MaxPool1d(2, padding=1),\n",
    "            self.activation(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Conv1d(64, 32, kernel_size=5, padding=2),\n",
    "            nn.MaxPool1d(2, padding=1),\n",
    "            self.activation(),\n",
    "        )\n",
    "        \n",
    "        self.num_features = 448\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.num_features, nb_hidden),\n",
    "            self.activation(),\n",
    "            nn.Linear(nb_hidden, 2)\n",
    "        )\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = Adam(self.parameters(), lr=0.001, weight_decay=0.01)\n",
    "        \n",
    "    def clear(self):\n",
    "        self.__init__(self.nb_hidden, self.activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_1D_Dropout(activation=nn.Tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train loss: 11.41447776556015. Train accuracy 51.90%. Test accuracy 59.00%\n",
      "Epoch 1: Train loss: 11.035064280033112. Train accuracy 61.71%. Test accuracy 52.00%\n",
      "Epoch 2: Train loss: 10.58230322599411. Train accuracy 70.25%. Test accuracy 58.00%\n",
      "Epoch 3: Train loss: 9.699862778186798. Train accuracy 74.05%. Test accuracy 66.00%\n",
      "Epoch 4: Train loss: 9.240520656108856. Train accuracy 74.68%. Test accuracy 73.00%\n",
      "Epoch 5: Train loss: 9.630765914916992. Train accuracy 71.52%. Test accuracy 65.00%\n",
      "Epoch 6: Train loss: 9.29376757144928. Train accuracy 78.80%. Test accuracy 63.00%\n",
      "Epoch 7: Train loss: 8.709371775388718. Train accuracy 76.58%. Test accuracy 63.00%\n",
      "Epoch 8: Train loss: 8.778748869895935. Train accuracy 79.75%. Test accuracy 66.00%\n",
      "Epoch 9: Train loss: 8.33068722486496. Train accuracy 79.43%. Test accuracy 68.00%\n",
      "Epoch 10: Train loss: 8.18165636062622. Train accuracy 79.11%. Test accuracy 67.00%\n",
      "Epoch 11: Train loss: 8.327183455228806. Train accuracy 79.11%. Test accuracy 65.00%\n",
      "Epoch 12: Train loss: 7.515120685100555. Train accuracy 86.08%. Test accuracy 70.00%\n",
      "Epoch 13: Train loss: 7.568652629852295. Train accuracy 81.65%. Test accuracy 66.00%\n",
      "Epoch 14: Train loss: 8.00174766778946. Train accuracy 74.05%. Test accuracy 65.00%\n",
      "Epoch 15: Train loss: 8.950363606214523. Train accuracy 80.38%. Test accuracy 69.00%\n",
      "Epoch 16: Train loss: 7.246097534894943. Train accuracy 78.48%. Test accuracy 67.00%\n",
      "Epoch 17: Train loss: 8.784933269023895. Train accuracy 76.27%. Test accuracy 62.00%\n",
      "Epoch 18: Train loss: 7.673408359289169. Train accuracy 81.96%. Test accuracy 67.00%\n",
      "Epoch 19: Train loss: 7.625480473041534. Train accuracy 81.96%. Test accuracy 74.00%\n",
      "Epoch 20: Train loss: 7.343815356492996. Train accuracy 80.06%. Test accuracy 74.00%\n",
      "Epoch 21: Train loss: 7.138110011816025. Train accuracy 83.54%. Test accuracy 64.00%\n",
      "Epoch 22: Train loss: 6.735333278775215. Train accuracy 84.18%. Test accuracy 69.00%\n",
      "Epoch 23: Train loss: 7.283996164798737. Train accuracy 85.44%. Test accuracy 70.00%\n",
      "Epoch 24: Train loss: 5.957573413848877. Train accuracy 84.81%. Test accuracy 73.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN_1D_Dropout(\n",
       "  (features): Sequential(\n",
       "    (0): Conv1d(28, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (1): Tanh()\n",
       "    (2): Dropout(p=0.1)\n",
       "    (3): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (4): MaxPool1d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (5): Tanh()\n",
       "    (6): Dropout(p=0.1)\n",
       "    (7): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (8): MaxPool1d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (9): Tanh()\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=448, out_features=50, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=50, out_features=2, bias=True)\n",
       "  )\n",
       "  (criterion): CrossEntropyLoss(\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_tr, y_tr, X_test=X_te, y_test=y_te, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate_n_hidden(CNN_1D_Dropout, X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D convolution + Batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([316, 28, 50]),\n",
       " torch.Size([316]),\n",
       " torch.Size([100, 28, 50]),\n",
       " torch.Size([100]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr, y_tr = Variable(train.X), Variable(train.y)\n",
    "X_te, y_te = Variable(test.X), Variable(test.y)\n",
    "\n",
    "X_tr.shape, y_tr.shape, X_te.shape, y_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_1D_BatchNorm(modelWrapper):\n",
    "    def __init__(self, nb_hidden=50, activation=nn.ReLU):\n",
    "        torch.manual_seed(0) \n",
    "        super(CNN_1D_BatchNorm, self).__init__()\n",
    "        \n",
    "        self.activation = activation\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.BatchNorm1d(28),\n",
    "            nn.Conv1d(28, 32, kernel_size=5, padding=2),\n",
    "            self.activation(),\n",
    "            \n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Conv1d(32, 32, kernel_size=5, padding=2),\n",
    "            self.activation(),\n",
    "            \n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Conv1d(32, 32, kernel_size=5, padding=2),\n",
    "            self.activation(),\n",
    "            \n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Conv1d(32, 32, kernel_size=5, padding=2),\n",
    "            nn.MaxPool1d(2, padding=1),\n",
    "            self.activation(),\n",
    "            \n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Conv1d(32, 32, kernel_size=5, padding=2),\n",
    "            nn.MaxPool1d(2),\n",
    "            self.activation(),\n",
    "            \n",
    "            nn.BatchNorm1d(32),\n",
    "        )\n",
    "        \n",
    "        self.num_features = 32*13\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.num_features, nb_hidden),\n",
    "            self.activation(),\n",
    "            nn.Linear(nb_hidden, 2)\n",
    "        )\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "#         self.optimizer = Adam(self.parameters(), lr=0.0001, weight_decay=1e-1)\n",
    "        self.optimizer = optim.Adamax(self.parameters(), lr=0.001, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_1D_BatchNorm(nb_hidden=250, activation=nn.PReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_tr, y_tr, X_test=X_te, y_test=y_te, epochs=100, batch_size=50, save_best_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.81, 0.83)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden = [np.asscalar(n) for n in np.arange(40, 201, 40)] # grid search on a parameter of the model\n",
    "\n",
    "# here we store all the scores obtained with the different number of hidden units\n",
    "modelScores = {\n",
    "    \"tr_scores\": [],\n",
    "    \"va_scores\": []\n",
    "}\n",
    "\n",
    "for n in n_hidden:\n",
    "    model = CNN_1D_BatchNorm(nb_hidden=250,(nb_hidden=n)\n",
    "    result = model.cross_validate(X_tr, y_tr, verbose=True, epochs=70)\n",
    "    \n",
    "    modelScores[\"tr_scores\"].append(np.mean(result[\"train_score\"]))\n",
    "    modelScores[\"va_scores\"].append(np.mean(result[\"test_score\"]))\n",
    "    \n",
    "plot_scores(n_hidden, \"#hidden units\", modelScores[\"tr_scores\"], modelScores[\"va_scores\"], log_scale=False)\n",
    "modelScores\n",
    "# best_n = n_hidden[np.argmax(modelScores[\"va_scores\"])]\n",
    "# print('Best #hidden units:', best_n)\n",
    "# print('Test score:',\n",
    "#       CNN_1D_Dropout(n)\n",
    "#       .fit(X_tr, y_tr, epochs=70)\n",
    "#       .score(X_te, y_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D dialated convolution + Batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([316, 28, 50]),\n",
       " torch.Size([316]),\n",
       " torch.Size([100, 28, 50]),\n",
       " torch.Size([100]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr, y_tr = Variable(train.X.clone()), Variable(train.y)\n",
    "X_te, y_te = Variable(test.X.clone()), Variable(test.y)\n",
    "\n",
    "X_tr.shape, y_tr.shape, X_te.shape, y_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_1D_BatchNorm_Dial(modelWrapper):\n",
    "    def __init__(self, nb_hidden=50, activation=nn.ReLU):\n",
    "        torch.manual_seed(0) \n",
    "        super(CNN_1D_BatchNorm_Dial, self).__init__()\n",
    "        \n",
    "        self.activation = activation\n",
    "        self.nb_hidden = nb_hidden\n",
    "        \n",
    "        n_filters = 32\n",
    "        self.features = nn.Sequential(\n",
    "            nn.BatchNorm1d(28),\n",
    "            nn.Conv1d(28, n_filters, kernel_size=3, padding=2, dilation=2),\n",
    "            self.activation(),\n",
    "            \n",
    "            nn.Dropout(p=0.1),\n",
    "            \n",
    "            nn.BatchNorm1d(n_filters),\n",
    "            nn.Conv1d(n_filters, n_filters, kernel_size=3, padding=2, dilation=2),\n",
    "            self.activation(),\n",
    "            \n",
    "            nn.BatchNorm1d(n_filters),\n",
    "            nn.Conv1d(n_filters, n_filters, kernel_size=5, padding=2),\n",
    "            self.activation(),\n",
    "            \n",
    "            nn.Dropout(p=0.1),\n",
    "            \n",
    "            nn.BatchNorm1d(n_filters),\n",
    "            nn.Conv1d(n_filters, n_filters, kernel_size=5, padding=4, dilation=2),\n",
    "            self.activation(),\n",
    "            \n",
    "            nn.Dropout(p=0.1),\n",
    "\n",
    "            nn.BatchNorm1d(n_filters),\n",
    "            nn.Conv1d(n_filters, 16, kernel_size=3, padding=1),\n",
    "            self.activation()\n",
    "        )\n",
    "        \n",
    "        self.num_features = 16*50\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.num_features, nb_hidden),\n",
    "            self.activation(),  \n",
    "    \n",
    "            # (1, nb_hidden)\n",
    "            nn.Linear(nb_hidden, 2)\n",
    "        )\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = Adam(self.parameters(), lr=0.001, weight_decay=1e-1)\n",
    "#         self.optimizer = optim.Adagrad(self.parameters())\n",
    "#         self.optimizer = optim.Adamax(self.parameters())\n",
    "#         self.optimizer = optim.ASGD(self.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_1D_BatchNorm_Dial(nb_hidden=50, activation=nn.ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train loss: 0.4014696665108204. Train accuracy 96.84%. Test accuracy 78.00%\n",
      "Epoch 1: Train loss: 0.4478878416121006. Train accuracy 95.25%. Test accuracy 78.00%\n",
      "Epoch 2: Train loss: 0.4421656168997288. Train accuracy 97.78%. Test accuracy 78.00%\n",
      "Epoch 3: Train loss: 0.5841380655765533. Train accuracy 94.30%. Test accuracy 83.00%\n",
      "Epoch 4: Train loss: 0.8554799966514111. Train accuracy 93.99%. Test accuracy 72.00%\n",
      "Epoch 5: Train loss: 0.7371013388037682. Train accuracy 94.30%. Test accuracy 76.00%\n",
      "Epoch 6: Train loss: 0.7103092446923256. Train accuracy 93.04%. Test accuracy 69.00%\n",
      "Epoch 7: Train loss: 0.6791842952370644. Train accuracy 93.35%. Test accuracy 74.00%\n",
      "Epoch 8: Train loss: 0.7118119411170483. Train accuracy 93.99%. Test accuracy 68.00%\n",
      "Epoch 9: Train loss: 0.8483623340725899. Train accuracy 89.87%. Test accuracy 78.00%\n",
      "Epoch 10: Train loss: 0.7330001965165138. Train accuracy 95.89%. Test accuracy 68.00%\n",
      "Epoch 11: Train loss: 0.9778911098837852. Train accuracy 94.62%. Test accuracy 71.00%\n",
      "Epoch 12: Train loss: 0.764783188700676. Train accuracy 93.67%. Test accuracy 77.00%\n",
      "Epoch 13: Train loss: 0.8022929951548576. Train accuracy 93.99%. Test accuracy 76.00%\n",
      "Epoch 14: Train loss: 0.7457943335175514. Train accuracy 95.25%. Test accuracy 77.00%\n",
      "Epoch 15: Train loss: 0.7353012003004551. Train accuracy 94.30%. Test accuracy 77.00%\n",
      "Epoch 16: Train loss: 0.7837948054075241. Train accuracy 94.62%. Test accuracy 74.00%\n",
      "Epoch 17: Train loss: 0.7656443119049072. Train accuracy 93.35%. Test accuracy 78.00%\n",
      "Epoch 18: Train loss: 0.6372103728353977. Train accuracy 97.78%. Test accuracy 73.00%\n",
      "Epoch 19: Train loss: 0.5798203945159912. Train accuracy 97.47%. Test accuracy 77.00%\n",
      "Epoch 20: Train loss: 0.4172235578298569. Train accuracy 94.94%. Test accuracy 77.00%\n",
      "Epoch 21: Train loss: 0.40139859914779663. Train accuracy 98.42%. Test accuracy 80.00%\n",
      "Epoch 22: Train loss: 0.29912005737423897. Train accuracy 97.15%. Test accuracy 76.00%\n",
      "Epoch 23: Train loss: 0.3317418750375509. Train accuracy 97.47%. Test accuracy 77.00%\n",
      "Epoch 24: Train loss: 0.38420376740396023. Train accuracy 98.10%. Test accuracy 78.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN_1D_BatchNorm(\n",
       "  (features): Sequential(\n",
       "    (0): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (1): Conv1d(28, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1)\n",
       "    (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (5): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "    (6): ReLU()\n",
       "    (7): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (8): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (9): ReLU()\n",
       "    (10): Dropout(p=0.1)\n",
       "    (11): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (12): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(4,), dilation=(2,))\n",
       "    (13): ReLU()\n",
       "    (14): Dropout(p=0.1)\n",
       "    (15): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (16): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (17): ReLU()\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=800, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=2, bias=True)\n",
       "  )\n",
       "  (criterion): CrossEntropyLoss(\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_tr, y_tr, X_test=X_te, y_test=y_te, epochs=25, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D convolution + Batch norm (bigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, y_tr = Variable(train.X.clone()), Variable(train.y)\n",
    "X_te, y_te = Variable(test.X.clone()), Variable(test.y)\n",
    "\n",
    "X_tr.shape, y_tr.shape, X_te.shape, y_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_1D_BatchNorm_Big(modelWrapper):\n",
    "    def __init__(self, nb_hidden=50, activation=nn.ReLU):\n",
    "        self.nb_hidden = nb_hidden\n",
    "        super(CNN_1D_BatchNorm_Big, self).__init__()\n",
    "        \n",
    "        self.activation = activation\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.BatchNorm1d(28),\n",
    "            nn.Conv1d(28, 32, kernel_size=5, padding=2),\n",
    "            self.activation(),\n",
    "            \n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Conv1d(32, 64, kernel_size=5, padding=2),\n",
    "            self.activation(),\n",
    "            \n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Conv1d(64, 64, kernel_size=5, padding=2),\n",
    "            nn.MaxPool1d(2, padding=1),\n",
    "            self.activation(),\n",
    "            \n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Conv1d(64, 32, kernel_size=5, padding=2),\n",
    "            nn.MaxPool1d(2, padding=1),\n",
    "            self.activation(),\n",
    "            \n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Conv1d(32, 32, kernel_size=5, padding=2),\n",
    "            self.activation(),\n",
    "            \n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Conv1d(32, 16, kernel_size=5, padding=2),\n",
    "            self.activation(),\n",
    "            \n",
    "            nn.BatchNorm1d(16),\n",
    "        )\n",
    "        \n",
    "        self.num_features = 16*14\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.num_features, nb_hidden),\n",
    "            self.activation(),\n",
    "            nn.Linear(nb_hidden, 2)\n",
    "        )\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = Adam(self.parameters(), lr=0.001, weight_decay=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_1D_BatchNorm_Big(activation=nn.PReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_tr, y_tr, X_test=X_te, y_test=y_te, epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D convolution + Batch norm + Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, y_tr = Variable(train.X.clone()), Variable(train.y)\n",
    "X_te, y_te = Variable(test.X.clone()), Variable(test.y)\n",
    "\n",
    "X_tr.shape, y_tr.shape, X_te.shape, y_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class residual_block(nn.Module):\n",
    "    def __init__(self, activation=nn.ReLU):\n",
    "        super(residual_block, self).__init__()\n",
    "        self.activation = activation\n",
    "        \n",
    "        num_filters = 32\n",
    "        self.features = nn.Sequential(\n",
    "            nn.BatchNorm1d(num_filters),\n",
    "            nn.Conv1d(num_filters, num_filters, kernel_size=3, padding=2, dilation=2),\n",
    "            self.activation(),\n",
    "            \n",
    "            nn.BatchNorm1d(num_filters),\n",
    "            nn.Conv1d(num_filters, num_filters, kernel_size=3, padding=1),\n",
    "            self.activation(),\n",
    "            \n",
    "            nn.BatchNorm1d(num_filters),\n",
    "            nn.Conv1d(num_filters, num_filters, kernel_size=3, padding=1),\n",
    "            self.activation(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):        \n",
    "        return x+self.features(x)\n",
    "\n",
    "class aggregated_residual_blocks(nn.Module):\n",
    "    def __init__(self, n_residual_blocks=2, activation=nn.ReLU):\n",
    "        super(aggregated_residual_blocks, self).__init__()\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.residual_blocks = nn.ModuleList()\n",
    "        for i in range(n_residual_blocks):\n",
    "            self.residual_blocks.append(residual_block(activation=activation))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = []\n",
    "        \n",
    "        for block in self.residual_blocks:\n",
    "            out.append(block(x))\n",
    "            \n",
    "        return sum(out)+x\n",
    "    \n",
    "class CNN_1D_BatchNorm_Residual(modelWrapper):\n",
    "    def __init__(self, nb_hidden=50, n_aggregated_residual_blocks=2, n_residual_blocks=2, activation=nn.ReLU):\n",
    "        # n_aggregated_residual_blocks: number of aggregated residual blocks (aggregated_residual_blocks)\n",
    "        # n_residual_blocks: number of residual blocks per aggregated residual block\n",
    "        \n",
    "        super(CNN_1D_BatchNorm_Residual, self).__init__()\n",
    "        \n",
    "        self.activation = activation\n",
    "        \n",
    "        self.features = [\n",
    "            nn.BatchNorm1d(28),\n",
    "            nn.Conv1d(28, 32, kernel_size=3, padding=2, dilation=2),\n",
    "            self.activation()\n",
    "        ]\n",
    "        for i in range(n_aggregated_residual_blocks):\n",
    "            self.features.append(aggregated_residual_blocks(n_residual_blocks))\n",
    "            self.features.append(nn.Dropout(0.15))\n",
    "        \n",
    "        self.features += [            \n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Conv1d(32, 16, kernel_size=3, padding=1),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.MaxPool1d(2),\n",
    "            self.activation(),\n",
    "        ]\n",
    "        self.features = nn.Sequential(*self.features)\n",
    "        \n",
    "        self.num_features = 16*25\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.num_features, nb_hidden),\n",
    "            self.activation(),\n",
    "            nn.Linear(nb_hidden, 2)\n",
    "        )\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.Adamax(self.parameters())\n",
    "#         self.optimizer = Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CNN_1D_BatchNorm_Residual(n_aggregated_residual_blocks=2, n_residual_blocks=5, activation=nn.ReLU)\n",
    "model = CNN_1D_BatchNorm_Residual(n_aggregated_residual_blocks=3, n_residual_blocks=1, activation=nn.ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train loss: 11.243237972259521. Train accuracy 51.90%. Test accuracy 46.00%\n",
      "Epoch 1: Train loss: 11.041338443756104. Train accuracy 57.59%. Test accuracy 59.00%\n",
      "Epoch 2: Train loss: 10.867946028709412. Train accuracy 69.30%. Test accuracy 55.00%\n",
      "Epoch 3: Train loss: 10.594859302043915. Train accuracy 68.99%. Test accuracy 62.00%\n",
      "Epoch 4: Train loss: 9.839361727237701. Train accuracy 72.78%. Test accuracy 67.00%\n",
      "Epoch 5: Train loss: 8.814906239509583. Train accuracy 76.27%. Test accuracy 74.00%\n",
      "Epoch 6: Train loss: 7.4753225445747375. Train accuracy 82.91%. Test accuracy 76.00%\n",
      "Epoch 7: Train loss: 6.616357833147049. Train accuracy 83.23%. Test accuracy 73.00%\n",
      "Epoch 8: Train loss: 5.707961589097977. Train accuracy 85.13%. Test accuracy 76.00%\n",
      "Epoch 9: Train loss: 4.751588121056557. Train accuracy 88.92%. Test accuracy 68.00%\n",
      "Epoch 10: Train loss: 4.25025101006031. Train accuracy 89.56%. Test accuracy 76.00%\n",
      "Epoch 11: Train loss: 3.1224499940872192. Train accuracy 82.91%. Test accuracy 73.00%\n",
      "Epoch 12: Train loss: 3.19545878469944. Train accuracy 80.06%. Test accuracy 70.00%\n",
      "Epoch 13: Train loss: 3.7053719758987427. Train accuracy 89.56%. Test accuracy 74.00%\n",
      "Epoch 14: Train loss: 2.6492408215999603. Train accuracy 87.03%. Test accuracy 74.00%\n",
      "Epoch 15: Train loss: 2.3530716374516487. Train accuracy 89.56%. Test accuracy 76.00%\n",
      "Epoch 16: Train loss: 2.9540945142507553. Train accuracy 90.19%. Test accuracy 71.00%\n",
      "Epoch 17: Train loss: 3.0725568551570177. Train accuracy 91.77%. Test accuracy 74.00%\n",
      "Epoch 18: Train loss: 1.5874352790415287. Train accuracy 94.30%. Test accuracy 75.00%\n",
      "Epoch 19: Train loss: 1.0968046337366104. Train accuracy 95.25%. Test accuracy 73.00%\n",
      "Epoch 20: Train loss: 0.7900709239766002. Train accuracy 95.57%. Test accuracy 73.00%\n",
      "Epoch 21: Train loss: 0.7211486222222447. Train accuracy 97.15%. Test accuracy 73.00%\n",
      "Epoch 22: Train loss: 0.4390001422725618. Train accuracy 96.52%. Test accuracy 74.00%\n",
      "Epoch 23: Train loss: 0.3051479705609381. Train accuracy 96.52%. Test accuracy 72.00%\n",
      "Epoch 24: Train loss: 0.22712554945610464. Train accuracy 96.52%. Test accuracy 70.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN_1D_BatchNorm_Residual(\n",
       "  (features): Sequential(\n",
       "    (0): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (1): Conv1d(28, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "    (2): ReLU()\n",
       "    (3): aggregated_residual_blocks(\n",
       "      (residual_blocks): ModuleList(\n",
       "        (0): residual_block(\n",
       "          (features): Sequential(\n",
       "            (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (2): ReLU()\n",
       "            (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (4): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (5): ReLU()\n",
       "            (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (7): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (8): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): Dropout(p=0.15)\n",
       "    (5): aggregated_residual_blocks(\n",
       "      (residual_blocks): ModuleList(\n",
       "        (0): residual_block(\n",
       "          (features): Sequential(\n",
       "            (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (2): ReLU()\n",
       "            (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (4): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (5): ReLU()\n",
       "            (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (7): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (8): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): Dropout(p=0.15)\n",
       "    (7): aggregated_residual_blocks(\n",
       "      (residual_blocks): ModuleList(\n",
       "        (0): residual_block(\n",
       "          (features): Sequential(\n",
       "            (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (2): ReLU()\n",
       "            (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (4): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (5): ReLU()\n",
       "            (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (7): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (8): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): Dropout(p=0.15)\n",
       "    (9): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (10): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (11): Dropout(p=0.1)\n",
       "    (12): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (13): ReLU()\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=400, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=2, bias=True)\n",
       "  )\n",
       "  (criterion): CrossEntropyLoss(\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_tr, y_tr, X_test=X_te, y_test=y_te, epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D conv horizontal and 1D conv vertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([316, 28, 50]),\n",
       " torch.Size([316]),\n",
       " torch.Size([100, 28, 50]),\n",
       " torch.Size([100]))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr, y_tr = Variable(train.X.clone()), Variable(train.y)\n",
    "X_te, y_te = Variable(test.X.clone()), Variable(test.y)\n",
    "\n",
    "X_tr.shape, y_tr.shape, X_te.shape, y_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_1D(nn.Module):\n",
    "    def __init__(self, in_channels, activation=nn.ReLU):\n",
    "        super(CNN_1D, self).__init__()\n",
    "        self.activation = activation\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(in_channels)\n",
    "        self.conv1 = nn.Conv1d(in_channels, 64, kernel_size=7, padding=3) \n",
    "        \n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv2 = nn.Conv1d(64, 64, kernel_size=5, padding=2)\n",
    "        \n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, in_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # (in_channels, 50)\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation(self.conv1(x))\n",
    "\n",
    "        # (64, 50)\n",
    "        x = self.bn2(x)\n",
    "        x = self.activation(self.conv2(x))\n",
    "\n",
    "        # (64, in_channels)\n",
    "        x = self.bn3(x)\n",
    "        x = self.activation(self.conv3(x))\n",
    "\n",
    "        return x\n",
    "    \n",
    "class conv2D(nn.Module):\n",
    "    def __init__(self, activation=nn.ReLU):\n",
    "        super(conv2D, self).__init__()\n",
    "        self.activation = activation\n",
    "                \n",
    "        self.bn1 = nn.BatchNorm1d(1)\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(3, 7), padding=(1, 3))\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5, padding=2)\n",
    "        \n",
    "        self.bn3 = nn.BatchNorm1d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 16, kernel_size=5, padding=2)\n",
    "#         self.conv4 = nn.Conv2d(32, 16, kernel_size=5, padding=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (1, 28, 50) -> (32, 14, 26)\n",
    "        x = self.activation(F.max_pool2d(self.conv1(self.bn1(x)), 2, padding=(0, 1)))\n",
    "\n",
    "        # (32, 14, 26) -> (32, 8, 14)\n",
    "        x = self.activation(F.max_pool2d(self.conv2(self.bn2(x)), (2, 2), padding=(1, 1)))\n",
    "\n",
    "        # (32, 8, 14) -> (16, 4, 7)\n",
    "        x = self.activation(F.max_pool2d(self.conv3(self.bn3(x)), 2))\n",
    "\n",
    "        return x\n",
    "        \n",
    "class horiz_vert_1D(modelWrapper):\n",
    "    def __init__(self, activation=nn.ReLU, nb_hidden=50):\n",
    "        super(horiz_vert_1D, self).__init__()\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.horiz = CNN_1D(28, activation=activation)\n",
    "        self.vert = CNN_1D(50, activation=activation)\n",
    "        \n",
    "        self.conv2D = conv2D()\n",
    "        self.conv2D_horiz = conv2D()\n",
    "        self.conv2D_vert = conv2D()\n",
    "        \n",
    "        self.fc1 = nn.Linear(448, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, 2)\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = Adam(self.parameters(), lr=0.001)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = self.conv2D_horiz(self.horiz(x).unsqueeze(1))\n",
    "        out2 = self.conv2D_vert(self.vert(x.transpose(1, 2)).transpose(1, 2).unsqueeze(1))\n",
    "        out3 = self.conv2D(x.unsqueeze(1))\n",
    "        \n",
    "        out = out1 + out2 + out3\n",
    "        \n",
    "        out = self.activation(self.fc1(out.view(-1, 448))) \n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = horiz_vert_1D(nb_hidden=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_tr, y_tr, X_test=X_te, y_test=y_te, epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual network with 2D convolutional layers + batch normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a channel to store the pixels image (so to apply the 2D convolutional layer)\n",
    "X_tr, y_tr = Variable(train.X.clone().unsqueeze(1)), Variable(train.y)\n",
    "X_te, y_te = Variable(test.X.clone().unsqueeze(1)), Variable(test.y)\n",
    "\n",
    "X_tr.shape, y_tr.shape, X_te.shape, y_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resudial network\n",
    "class BasicBlock():\n",
    "    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.droprate = dropRate\n",
    "        self.equalInOut = (in_planes == out_planes)\n",
    "        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
    "                               padding=0, bias=False) or None\n",
    "    def forward(self, x):\n",
    "        if not self.equalInOut:\n",
    "            x = self.relu1(self.bn1(x))\n",
    "        else:\n",
    "            out = self.relu1(self.bn1(x))\n",
    "        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n",
    "        if self.droprate > 0:\n",
    "            out = F.dropout(out, p=self.droprate, training=self.training)\n",
    "        out = self.conv2(out)\n",
    "        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n",
    "    \n",
    "class NetworkBlock():\n",
    "    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n",
    "        super(NetworkBlock, self).__init__()\n",
    "        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n",
    "    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n",
    "        layers = []\n",
    "        for i in range(nb_layers):\n",
    "            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "class WideResNet(, modelWrapper):\n",
    "    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n",
    "        super(WideResNet, self).__init__()\n",
    "        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n",
    "        assert((depth - 4) % 6 == 0)\n",
    "        n = int((depth - 4) / 6)\n",
    "        block = BasicBlock\n",
    "        # 1st conv before any network block\n",
    "        self.conv1 = nn.Conv2d(1, nChannels[0], kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        # 1st block\n",
    "        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n",
    "        # 2nd block\n",
    "        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n",
    "        # 3rd block\n",
    "        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n",
    "        # global average pooling and classifier\n",
    "        self.bn1 = nn.BatchNorm2d(nChannels[3])\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        #self.fc = nn.Linear(nChannels[3], num_classes)\n",
    "        #self.nChannels = nChannels[3]\n",
    "        self.fc = nn.Linear(1152, num_classes)\n",
    "        self.nChannels = 1152\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = Adam(self.parameters(), lr=0.01)\n",
    "\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.Conv2d):\n",
    "#                 n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "#                 m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "#             elif isinstance(m, nn.BatchNorm2d):\n",
    "#                 m.weight.data.fill_(1)\n",
    "#                 m.bias.data.zero_()\n",
    "#             elif isinstance(m, nn.Linear):\n",
    "#                 m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.size())\n",
    "        out = self.conv1(x)\n",
    "        #print(out.size())\n",
    "        out = self.block1(out)\n",
    "        #print(out.size())\n",
    "        out = self.block2(out)\n",
    "        #print(out.size())\n",
    "        out = self.block3(out)\n",
    "        #print(out.size())\n",
    "        out = self.relu(self.bn1(out))\n",
    "        #print(out.size())\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        #print(out.size())\n",
    "        out = self.fc(out.view(-1, self.nChannels))\n",
    "        #print(out.size())\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WideResNet(depth=16, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_tr, y_tr, X_test=X_te, y_test=y_te, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

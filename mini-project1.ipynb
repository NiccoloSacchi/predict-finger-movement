{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <h1>Mini-project1</h1>\n",
    "    <h2>Predict the laterality of upcoming finger movements</h2>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import dlc_bci as bci\n",
    "from types import SimpleNamespace \n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# baselines\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import torch \n",
    "from torch.nn import Conv2d, Linear, functional, Module, CrossEntropyLoss\n",
    "from torch import Tensor\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from helpers import *\n",
    "from modelWrapper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download/load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, y_tr = bci.load(root='./data_bci')\n",
    "print(str(type(X_tr)), X_tr.size())\n",
    "print(str(type(y_tr)), y_tr.size())\n",
    "\n",
    "X_te, y_te = bci.load(root='./data_bci', train=False)\n",
    "print(str(type(X_te)), X_te.size())\n",
    "print(str(type(y_te)), y_te.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 45\n",
    "plt.imshow(X_tr[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Organize the dataset in train and test by also converting the X in array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = SimpleNamespace()\n",
    "train.X = SimpleNamespace()\n",
    "train.X.variable = Variable(X_tr.unsqueeze(1))\n",
    "train.X.numpy = X_tr.numpy().reshape(X_tr.shape[0], -1)\n",
    "train.y = SimpleNamespace()\n",
    "train.y.variable = Variable(y_tr)\n",
    "train.y.numpy = y_tr.numpy()\n",
    "\n",
    "test = SimpleNamespace()\n",
    "test.X = SimpleNamespace()\n",
    "test.X.variable = Variable(X_te.unsqueeze(1))\n",
    "test.X.numpy = X_te.numpy().reshape(X_te.shape[0], -1)\n",
    "test.y = SimpleNamespace()\n",
    "test.y.variable = Variable(y_te)\n",
    "test.y.numpy = y_te.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.logspace(-6, 6, 20) # grid search on a parameter of the model\n",
    "\n",
    "# here we store all the scores obtained with the different lambdas\n",
    "logreg = {\n",
    "    \"tr_scores\": [],\n",
    "    \"va_scores\": []\n",
    "}\n",
    "\n",
    "for lambda_ in lambdas:\n",
    "    result = cross_validate(LogisticRegression(C=lambda_), train.X.numpy, train.y.numpy, cv=10, return_train_score=True)\n",
    "    \n",
    "    logreg[\"tr_scores\"].append(np.mean(result[\"train_score\"]))\n",
    "    logreg[\"va_scores\"].append(np.mean(result[\"test_score\"]))\n",
    "    \n",
    "plot_scores(lambdas, \"lambda\", logreg[\"tr_scores\"], logreg[\"va_scores\"], log_scale=True)\n",
    "\n",
    "best_lambda = lambdas[np.argmax(logreg[\"va_scores\"])]\n",
    "print('Best lambda:', best_lambda)\n",
    "print('Test score:', \n",
    "      LogisticRegression(C=best_lambda)\n",
    "      .fit(train.X.numpy, train.y.numpy)\n",
    "      .score(test.X.numpy, test.y.numpy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = np.arange(5, 100, 10) # grid search on a parameter of the model\n",
    "\n",
    "# here we store all the scores obtained with the different depths\n",
    "randForest = {\n",
    "    \"tr_scores\": [],\n",
    "    \"va_scores\": []\n",
    "}\n",
    "\n",
    "for depth in depths:\n",
    "    result = cross_validate(\n",
    "        RandomForestClassifier(n_estimators=100, max_depth=depth, n_jobs=-1, random_state=1), \n",
    "        train.X.numpy, train.y.numpy, cv=10, return_train_score=True)\n",
    "    \n",
    "    randForest[\"tr_scores\"].append(np.mean(result[\"train_score\"]))\n",
    "    randForest[\"va_scores\"].append(np.mean(result[\"test_score\"]))\n",
    "    \n",
    "plot_scores(depths, \"depth\", randForest[\"tr_scores\"], randForest[\"va_scores\"], log_scale=False)\n",
    "\n",
    "best_depth = depths[np.argmax(randForest[\"va_scores\"])]\n",
    "print('Best depth:', best_depth)\n",
    "print('Test score:',\n",
    "      RandomForestClassifier(n_estimators=100, max_depth=depth, n_jobs=-1, random_state=1)\n",
    "      .fit(train.X.numpy, train.y.numpy)\n",
    "      .score(test.X.numpy, test.y.numpy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train.X.numpy)\n",
    "X_tr_scaled = scaler.transform(train.X.numpy)\n",
    "X_te_scaled = scaler.transform(test.X.numpy)\n",
    "print(\"standard deviation average:\", X_tr_scaled.std(axis=0).mean())\n",
    "print(\"mean average:\", X_tr_scaled.mean(axis=0).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "pca.fit(X_tr_scaled)\n",
    "X_tr_scaled = pca.transform(X_tr_scaled)\n",
    "X_te_scaled = pca.transform(X_te_scaled)\n",
    "X_tr_scaled.shape, X_te_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ks = np.arange(1, 10, 1) # grid search on a parameter of the model\n",
    "\n",
    "# here we store all the scores obtained with the different number of neighbors\n",
    "nearestNeig = {\n",
    "    \"tr_scores\": [],\n",
    "    \"va_scores\": []\n",
    "}\n",
    "\n",
    "for k in Ks:\n",
    "    result = cross_validate(\n",
    "        KNeighborsClassifier(n_neighbors=k), \n",
    "        X_tr_scaled, train.y.numpy, cv=10, return_train_score=True)\n",
    "    \n",
    "    nearestNeig[\"tr_scores\"].append(np.mean(result[\"train_score\"]))\n",
    "    nearestNeig[\"va_scores\"].append(np.mean(result[\"test_score\"]))\n",
    "    \n",
    "plot_scores(Ks, \"# Neighbors\", nearestNeig[\"tr_scores\"], nearestNeig[\"va_scores\"], log_scale=False)\n",
    "\n",
    "best_k = Ks[np.argmax(nearestNeig[\"va_scores\"])]\n",
    "print('Best k:', best_k)\n",
    "print('Test score:', \n",
    "      KNeighborsClassifier(n_neighbors=k)\n",
    "      .fit(X_tr_scaled, train.y.numpy)\n",
    "      .score(X_te_scaled, test.y.numpy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the network with two convolutional layers\n",
    "class CNN(Module, modelWrapper):\n",
    "    def __init__(self, nb_hidden):\n",
    "        self.nb_hidden = nb_hidden\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = Conv2d(1, 32, kernel_size=(3, 7), padding=(1, 3)) \n",
    "        self.conv2 = Conv2d(32, 64, kernel_size=5, padding=2)\n",
    "        self.conv3 = Conv2d(64, 32, kernel_size=5, padding=2)\n",
    "#         self.conv4 = Conv2d(32, 16, kernel_size=5, padding=2)\n",
    "        \n",
    "        self.fc1 = Linear(384, nb_hidden)\n",
    "        self.fc2 = Linear(nb_hidden, 2)\n",
    "        \n",
    "        self.criterion = CrossEntropyLoss()\n",
    "        self.optimizer = Adam(self.parameters(), lr=0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (1, 28, 50)\n",
    "        x = F.leaky_relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        # (32, 14, 25)\n",
    "        x = F.leaky_relu(F.max_pool2d(self.conv2(x), (2, 5)))\n",
    "        # (64, 7, 5)\n",
    "        x = F.leaky_relu(F.max_pool2d(self.conv3(x), 2, padding=(1, 1)))\n",
    "        # (32, 4, 3)\n",
    "#         x = F.relu(self.conv4(x))\n",
    "#         # (16, 4, 3)\n",
    "        \n",
    "        x = F.leaky_relu(self.fc1(x.view(-1, 384)))  \n",
    "        # (1, nb_hidden)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def reset(self):\n",
    "        self.__init__(self.nb_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train.X.variable, train.y.variable, X_test=test.X.variable, y_test=test.y.variable, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(train.X.variable).shape, train.X.variable.shape\n",
    "# model.score(train.X.variable, train.y.variable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cv]",
   "language": "python",
   "name": "conda-env-cv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
